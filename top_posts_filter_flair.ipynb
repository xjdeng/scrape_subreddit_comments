{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66754c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import re\n",
    "import random\n",
    "import bs4, markdown\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a703ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "credential_file = \"credentials.key\"\n",
    "\n",
    "try:\n",
    "    with open(credential_file, 'r') as f:\n",
    "        creds = f.read().split('\\n')\n",
    "    personal = creds[0]\n",
    "    secret = creds[1]\n",
    "    username = creds[2]\n",
    "    password = creds[3]\n",
    "except IOError as e:\n",
    "    print(\"You didn't create a credential file! Please see sample_credentials.key\")\n",
    "    print(\"Then go to http://www.storybench.org/how-to-scrape-reddit-with-python/\")\n",
    "    print(\"And register a new app named fastai_reddit in your reddit account.\")\n",
    "    print(\"And insert the values into sample_credentials.key and save it as {}.\".format(credential_file))\n",
    "    raise(e)\n",
    "\n",
    "def noquotes(text):\n",
    "    \"\"\"\n",
    "This function first stated out as a way to remove markdown quotes from raw reddit markdown text but now it's more of a\n",
    "general purpose text parser, but the name hasn't changed.\n",
    "    \"\"\"\n",
    "    #https://stackoverflow.com/questions/761824/python-how-to-convert-markdown-formatted-text-to-text\n",
    "    t1 = re.sub(\">.+?(\\n|$)\",\"\",text).replace(\"\\\\n\",\"\").replace(\"\\\\\",\"\")\n",
    "    html = markdown.markdown(t1)\n",
    "    t2 = ''.join(bs4.BeautifulSoup(html, 'lxml').findAll(text=True))\n",
    "    \n",
    "    return t2    \n",
    "\n",
    "reddit = praw.Reddit(client_id=personal, client_secret=secret, user_agent='fastai_reddit', username=username, \\\n",
    "                     password=password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e587e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mbti = set(['INTP','INTJ','INFJ','INFP',\\\n",
    "               'ENTP','ENTJ','ENFJ','ENFP',\\\n",
    "               'ESTP','ESTJ','ESFJ','ESFP',\n",
    "               'ISTP','ISTJ','ISFJ','ISFP'])\n",
    "len(all_mbti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08d35b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mbti(target_mbti = \"INTP\", limit = 1000):\n",
    "    subreddit = reddit.subreddit(target_mbti)\n",
    "    bad_mbti = copy.copy(all_mbti)\n",
    "    bad_mbti.remove(target_mbti)\n",
    "    bad_mbti = list(bad_mbti)\n",
    "    top = list(subreddit.top(limit=limit))\n",
    "    new = list(subreddit.new(limit=limit))\n",
    "    rising = list(subreddit.rising(limit=limit))\n",
    "    controversial = list(subreddit.controversial(limit=limit))\n",
    "    gilded = list(subreddit.gilded(limit=limit))\n",
    "    posts = list(set(top + new + rising + controversial + gilded))\n",
    "    \n",
    "    def query_flair(c):\n",
    "        result = True\n",
    "        flair = c.author_flair_text\n",
    "        if not flair:\n",
    "            return True\n",
    "        if len(flair) > 0:\n",
    "            flairU = flair.upper()\n",
    "            for mbti in bad_mbti:\n",
    "                if mbti in flairU:\n",
    "                    result = False\n",
    "                    break\n",
    "        return result\n",
    "\n",
    "    def get_comment_text(comment):\n",
    "        comments = []\n",
    "        if isinstance(comment, praw.models.MoreComments):\n",
    "            while True:\n",
    "                try:\n",
    "                    newcomments = comment.comments()\n",
    "                    break\n",
    "                except praw.exceptions.APIException as e:\n",
    "                    if e.response.status_code == 500:\n",
    "                        print('Received 500 error. Sleeping for 1 minute...')\n",
    "                        time.sleep(60)\n",
    "                    else:\n",
    "                        raise e\n",
    "            for n in newcomments:\n",
    "                comments += get_comment_text(n)\n",
    "        else:\n",
    "            while True:\n",
    "                try:\n",
    "                    if query_flair(comment):\n",
    "                        comments.append(noquotes(comment.body))\n",
    "                    break\n",
    "                except praw.exceptions.APIException as e:\n",
    "                    if e.response.status_code == 500:\n",
    "                        print('Received 500 error. Sleeping for 1 minute...')\n",
    "                        time.sleep(60)\n",
    "                    else:\n",
    "                        raise e\n",
    "        return comments\n",
    "\n",
    "    alltext = []\n",
    "    for p in tqdm(posts):\n",
    "        try:\n",
    "            tmp = noquotes(p.selftext)\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        if len(tmp) > 0:\n",
    "            if query_flair(p):\n",
    "                alltext.append(tmp)\n",
    "        for c in p.comments.list():\n",
    "            alltext += get_comment_text(c)\n",
    "    df = pd.DataFrame()\n",
    "    df['type'] = [target_mbti]*len(alltext)\n",
    "    df['posts'] = alltext\n",
    "    df.to_csv(\"{}.csv\".format(target_mbti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45ed967e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESTP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2377/2377 [40:29<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESFP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2089/2089 [35:14<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESFJ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1568/1568 [26:27<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISTJ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2378/2378 [40:02<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESTJ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1281/1281 [21:46<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISFJ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2489/2489 [41:41<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2960/2960 [54:40<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFJ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2956/2956 [56:25<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2949/2949 [1:02:14<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENFP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2968/2968 [53:37<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTJ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2968/2968 [1:04:47<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 3020/3020 [1:04:11<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISFP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2685/2685 [45:21<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTJ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2871/2871 [53:44<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISTP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2775/2775 [48:46<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENFJ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2704/2704 [47:19<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "for mbti in all_mbti:\n",
    "    print(mbti)\n",
    "    run_mbti(mbti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5d15ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [pd.read_csv(\"{}.csv\".format(m), index_col = 0) for m in all_mbti]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64d51b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06a78afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>Hey, y’all. Cheers to us reaching 8,000 member...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>You boys and girls keep being awesome!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>I'm unsure when he lies and when he doesnt.. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>I think you’re in the wrong sub.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESTP</td>\n",
       "      <td>Don't care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  ESTP  Hey, y’all. Cheers to us reaching 8,000 member...\n",
       "1  ESTP             You boys and girls keep being awesome!\n",
       "2  ESTP  I'm unsure when he lies and when he doesnt.. I...\n",
       "3  ESTP                   I think you’re in the wrong sub.\n",
       "4  ESTP                                         Don't care"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cadd483",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"mbti2.csv\", index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf1f2543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1002166"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafe801e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
